{"basics":{"name":"Jayant Taneja","label":"Machine Learning Engineer","image":"","email":"","phone":"","url":"https://jayanttaneja.github.io/","summary":"An Engineer working at the intersection of Recommender Systems, Generative AI and Natural Language Processing","location":{"address":"NOIDA","postalCode":"","city":"","countryCode":"IN","region":""},"profiles":[{"network":"Linkedin","username":"jayant-taneja","url":"https://www.linkedin.com/in/jayant-taneja/"}]},"work":[{"name":"Samsung R&D Institute India, Delhi","position":"Software Engineer-Machine Learning","location":"India","url":"","startDate":"2024-07","endDate":"","summary":"Generative AI Research, Recommender Systems, and a lot of new concept development for intelligent screen experiences.","highlights":["EMNLP 2025 findings acceptance","ICML 2025 Workshop (Oral) acceptance"]},{"name":"Swiggy","position":"Analytics Intern","location":"India","url":"","startDate":"2023-11","endDate":"2024-06","summary":"Worked on improving the in-house Payments Platform by analyzing and deriving insights from terabyte scale data.","highlights":["Built a brand new payment monitoring system from scratch","Worked with a ton of brilliant folks"]}],"publications":[{"name":"Offloaded Reasoning: Efficient Inference for Large Language Models via Modular Reasoning and Refinement","publisher":"ICML 2025 Oral (TTODLer-FM Workshop)","releaseDate":"2025","url":"https://openreview.net/forum?id=kwhQ6Btu5E","summary":"Large language models (LLMs) demonstrate strong reasoning capabilities but are expensive to run at inference time, limiting their practical deployment. We propose Offloaded Reasoning (OR), a modular strategy where a lightweight model generates intermediate reasoning traces that are then used by a larger model to produce the final answer. We further introduce Offloaded Reasoning with Refinement (ORR), where the large model first edits or improves the reasoning trace before answering. Unlike token-level acceleration methods, OR and ORR operate at the reasoning level and require no retraining of the large model. Experiments on GSM8K and Math500 show that OR achieves up to 8x faster inference than full large-model reasoning with minimal accuracy loss, while ORR recovers or exceeds full accuracy at substantially lower cost. Our results highlight the potential of modular, delegation-based reasoning for building more efficient and adaptable LLM systems."}],"education":[{"institution":"J.C. Bose University Of Science and Technology, YMCA, Faridabad","location":"Haryana, India","url":"https://jcboseust.ac.in/","area":"Computer Science and Engineering","studyType":"Bachelor's Degree (B.Tech)","startDate":"2020","endDate":"2024","score":"","courses":[]}],"volunteer":[{"organization":"Manan-A Technosurge","location":"India","position":"Joint Secretary","url":"https://in.linkedin.com/company/manan-ymca","startDate":"2022-07","endDate":"2024-07","summary":"As a joint secretary of 'Manan-A Technosurge', the coding club of my university, I co-led various coding events and represented the college at external coding contests.","highlights":[]}],"awards":[],"certificates":[{"name":"Machine Learning","date":"2021-11","issuer":"Stanford University","url":"https://coursera.org/share/543e7ec86d72332a3a18aa1addb8aa39","icon":""},{"name":"Deep Learning","date":"2022-06","issuer":"Deeplearning.ai","url":"https://coursera.org/share/4dd9f0e17bbdf8bfebb8453ff7b22d43","icon":""}],"skills":[{"name":"Programming Languages","level":"","icon":"fa-solid fa-code","keywords":["Python","SQL","C++"]},{"name":"Libraries/Frameworks","level":"","icon":"fa-solid fa-cube","keywords":["PyTorch","PySpark","vLLM","Huggingface Transformers","FastAPI","Streamlit","Model Context Protocol (MCP)"]},{"name":"GenAI Tools/Related Technologies","level":"","icon":"fa-solid fa-hexagon-nodes-bolt","keywords":["vLLM (LLM inference)","ChromaDB (vector database)"]},{"name":"Databases","level":"","icon":"fa-solid fa-database","keywords":["PostgreSQL","Snowflake SQL","Databricks SQL","AWS RDS"]},{"name":"Other Tools","level":"","icon":"fa-solid fa-wrench","keywords":["AWS EC2","AWS EMR","Git","GitHub","Jupyter"]}],"languages":[{"language":"English","fluency":"Fluent","icon":""},{"language":"Hindi","fluency":"Native speaker","icon":""}],"interests":[{"name":"Artificial Intelligence","icon":"fa-solid fa-tag","keywords":["Information Retrieval","Natural Language Processing","Recommender Systems","Generative AI"]}],"references":[],"projects":[]}